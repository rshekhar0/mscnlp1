# Tokenization using NLTK
import nltk 
from nltk.tokenize import word_tokenize 
# Create a string input 
input_str = "I love to study Natural Language Processing in Python" 
# Tokenize the input string 
tokens = word_tokenize(input_str) 
# Print tokens 
print("Tokenized Output:") 
print("=================") 
print(tokens)